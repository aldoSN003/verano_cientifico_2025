# -*- coding: utf-8 -*-
"""original-vit-lemon-classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FsZ0ONhu8oH7We2sejfdJi_IHz703amZ
"""

import torch
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.1f} GB")

!pip install -U datasets

# ============================================================================
# CLASIFICACIÓN DE ENFERMEDADES DE LIMÓN USANDO VISION TRANSFORMER (ViT)
# ============================================================================

# Importar librerías necesarias
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import pandas as pd
from datasets import load_dataset
from transformers import (
    AutoImageProcessor,
    AutoModelForImageClassification,
    Trainer,
    TrainingArguments,
    pipeline
)
from sklearn.metrics import (
    accuracy_score,
    precision_recall_fscore_support,
    confusion_matrix
)
from huggingface_hub import notebook_login
import warnings
warnings.filterwarnings('ignore')

# Configuración de estilo para gráficos
plt.style.use('default')
sns.set_palette("husl")

class LemonDiseaseClassifier:
    def __init__(self, dataset_name="AldoSN/lemon-leaf-disease-dataset", model_name="google/vit-base-patch16-224"):
        self.dataset_name = dataset_name
        self.model_name = model_name
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # Etiquetas de clases para el dataset
        self.class_labels = [
            "Anthracnose", "Bacterial Blight", "Citrus Canker", "Curl Virus",
            "Deficiency Leaf", "Dry Leaf", "Healthy Leaf", "Sooty Mould", "Spider Mites"
        ]

        # Inicializar componentes
        self.processor = None
        self.model = None
        self.dataset = None
        self.trainer = None

        print(f"Inicializando clasificador de enfermedades de limón")
        print(f"Dataset: {self.dataset_name}")
        print(f"Modelo: {self.model_name}")
        print(f"Dispositivo: {self.device}")

    def load_dataset_and_processor(self):
        """Cargar dataset e inicializar procesador"""
        print("Cargando dataset...")
        self.dataset = load_dataset(self.dataset_name)

        print("Cargando procesador...")
        self.processor = AutoImageProcessor.from_pretrained(self.model_name)

        print(f"Dataset cargado - Entrenamiento: {len(self.dataset['train'])}, Prueba: {len(self.dataset['test'])}")

        return self.dataset, self.processor

    def preprocess_data(self):
        """Preprocesar imágenes para entrenamiento"""
        print("Preprocesando datos...")

        def preprocess_function(examples):
            # Procesar imágenes
            images = [image.convert("RGB") for image in examples["image"]]
            inputs = self.processor(images, return_tensors="pt")
            inputs["labels"] = examples["label"]
            return inputs

        # Aplicar preprocesamiento
        self.dataset = self.dataset.map(
            preprocess_function,
            batched=True,
            remove_columns=["image"]
        )

        # Configurar formato para PyTorch
        self.dataset.set_format("torch")

        print("Preprocesamiento completado")
        return self.dataset

    def initialize_model(self):
        """Inicializar modelo para fine-tuning"""
        print("Inicializando modelo...")

        # Cargar modelo con número correcto de etiquetas
        self.model = AutoModelForImageClassification.from_pretrained(
            self.model_name,
            num_labels=len(self.class_labels),
            id2label={i: label for i, label in enumerate(self.class_labels)},
            label2id={label: i for i, label in enumerate(self.class_labels)},
            ignore_mismatched_sizes=True
        )
        self.model = self.model.to(self.device)

        print(f"Modelo inicializado con {len(self.class_labels)} clases")
        return self.model

    def compute_metrics(self, eval_pred):
        """Calcular métricas de evaluación"""
        predictions, labels = eval_pred
        predictions = np.argmax(predictions, axis=1)

        # Calcular métricas
        accuracy = accuracy_score(labels, predictions)
        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')

        return {
            'accuracy': accuracy,
            'f1': f1,
            'precision': precision,
            'recall': recall
        }

    def setup_training_args(self, output_dir="./vit-lemon-classifier", num_epochs=10, batch_size=64):
        """Argumentos de entrenamiento"""
        return TrainingArguments(
            output_dir=output_dir,
            num_train_epochs=num_epochs,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            warmup_steps=500,
            weight_decay=0.01,
            logging_dir=f"{output_dir}/logs",
            logging_steps=10,
            eval_strategy="epoch",
            save_strategy="epoch",
            load_best_model_at_end=True,
            metric_for_best_model="f1",
            greater_is_better=True,
            remove_unused_columns=False,
            push_to_hub=False,
            dataloader_pin_memory=False,
            run_name="vit-lemon-classifier"
        )

    def train_model(self, training_args):
        """Entrenar el modelo"""
        print("Iniciando entrenamiento...")

        # Inicializar trainer
        self.trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=self.dataset["train"],
            eval_dataset=self.dataset["test"],
            compute_metrics=self.compute_metrics,
            tokenizer=self.processor,
        )

        # Entrenar modelo
        train_result = self.trainer.train()

        # Guardar modelo
        self.trainer.save_model()

        print("Entrenamiento completado")

        # Guardar historial de entrenamiento
        self.save_training_history(train_result, training_args.output_dir)

        return train_result

    def evaluate_model(self, output_dir="./vit-lemon-classifier"):
        """Evaluación completa del modelo con métricas detalladas"""
        print("Evaluando modelo...")

        # Obtener predicciones
        predictions = self.trainer.predict(self.dataset["test"])
        y_pred = np.argmax(predictions.predictions, axis=1)
        y_true = predictions.label_ids

        # Calcular métricas detalladas
        accuracy = accuracy_score(y_true, y_pred)
        precision, recall, f1, support = precision_recall_fscore_support(
            y_true, y_pred, average=None, labels=range(len(self.class_labels))
        )

        # Métricas generales
        precision_weighted = precision_recall_fscore_support(y_true, y_pred, average='weighted')[0]
        recall_weighted = precision_recall_fscore_support(y_true, y_pred, average='weighted')[1]
        f1_weighted = precision_recall_fscore_support(y_true, y_pred, average='weighted')[2]

        # Imprimir resultados
        print(f"\nRESULTADOS DE EVALUACIÓN:")
        print(f"=" * 50)
        print(f"Precisión General: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"Precisión Ponderada: {precision_weighted:.4f}")
        print(f"Recall Ponderado: {recall_weighted:.4f}")
        print(f"F1-Score Ponderado: {f1_weighted:.4f}")
        print(f"=" * 50)

        # Métricas por clase
        print(f"\nMÉTRICAS POR CLASE:")
        print(f"{'Clase':<20} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}")
        print("-" * 70)
        for i, (class_name, prec, rec, f1_score, supp) in enumerate(zip(self.class_labels, precision, recall, f1, support)):
            print(f"{class_name:<20} {prec:<10.4f} {rec:<10.4f} {f1_score:<10.4f} {supp:<10}")

        # Matriz de confusión
        cm = confusion_matrix(y_true, y_pred)
        self.plot_confusion_matrix(cm, output_dir)

        # Guardar métricas en archivo
        metrics_dict = {
            "overall_metrics": {
                "accuracy": float(accuracy),
                "precision": float(precision_weighted),
                "recall": float(recall_weighted),
                "f1_score": float(f1_weighted)
            },
            "per_class_metrics": {
                self.class_labels[i]: {
                    "precision": float(precision[i]),
                    "recall": float(recall[i]),
                    "f1_score": float(f1[i]),
                    "support": int(support[i])
                }
                for i in range(len(self.class_labels))
            }
        }

        with open(f"{output_dir}/evaluation_metrics.json", "w") as f:
            json.dump(metrics_dict, f, indent=2)

        print(f"\nMétricas guardadas en {output_dir}/evaluation_metrics.json")
        print(f"Matriz de confusión guardada en {output_dir}/confusion_matrix.png")

        return metrics_dict

    def plot_confusion_matrix(self, cm, output_dir):
        """Graficar y guardar matriz de confusión"""
        plt.figure(figsize=(12, 10))
        sns.heatmap(
            cm,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=self.class_labels,
            yticklabels=self.class_labels,
            cbar_kws={'label': 'Count'}
        )
        plt.title('Matriz de Confusión - Clasificación de Enfermedades de Limón', fontsize=16, fontweight='bold')
        plt.xlabel('Etiqueta Predicha', fontsize=12)
        plt.ylabel('Etiqueta Verdadera', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.savefig(f"{output_dir}/confusion_matrix.png", dpi=300, bbox_inches='tight')
        plt.show()



    def save_training_history(self, train_result, output_dir):
        """Guardar historial de entrenamiento para gráficos posteriores"""
        # Extraer logs de entrenamiento
        log_history = self.trainer.state.log_history

        # Separar logs de entrenamiento y evaluación
        train_logs = []
        eval_logs = []

        for log in log_history:
            if 'loss' in log and 'eval_loss' not in log:
                train_logs.append(log)
            elif 'eval_loss' in log:
                eval_logs.append(log)

        # Guardar en JSON para uso posterior
        training_history = {
            'train_logs': train_logs,
            'eval_logs': eval_logs
        }

        with open(f"{output_dir}/training_history.json", "w") as f:
            json.dump(training_history, f, indent=2)

        print(f"Historial de entrenamiento guardado en {output_dir}/training_history.json")

        return training_history

    def plot_training_curves(self, output_dir="./vit-lemon-classifier"):
        """Graficar curvas de loss y accuracy de entrenamiento y validación"""
        # Cargar historial de entrenamiento
        try:
            with open(f"{output_dir}/training_history.json", "r") as f:
                history = json.load(f)
        except FileNotFoundError:
            print("Historial de entrenamiento no encontrado. Asegúrate de entrenar el modelo primero.")
            return

        # Extraer datos
        train_logs = history['train_logs']
        eval_logs = history['eval_logs']

        # Crear DataFrames
        train_df = pd.DataFrame(train_logs)
        eval_df = pd.DataFrame(eval_logs)

        # Calcular épocas para logs de entrenamiento
        if not train_df.empty and 'step' in train_df.columns:
            if not eval_df.empty and len(eval_df) > 1 and 'epoch' in eval_df.columns:
                total_steps = train_df['step'].max()
                total_epochs = eval_df['epoch'].max()
                steps_per_epoch = total_steps / total_epochs
                train_df['epoch'] = train_df['step'] / steps_per_epoch
            else:
                # Estimar épocas basado en el número de logs
                train_df['epoch'] = train_df['step'] / (train_df['step'].max() / 10)

        # Crear subplots
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

        # Graficar loss de entrenamiento
        if 'loss' in train_df.columns and 'epoch' in train_df.columns:
            ax1.plot(train_df['epoch'], train_df['loss'], 'b-', label='Training Loss', linewidth=2, alpha=0.7)
            ax1.set_title('Training Loss', fontsize=14, fontweight='bold')
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Loss')
            ax1.grid(True, alpha=0.3)
            ax1.legend()

        # Graficar loss de validación
        if 'eval_loss' in eval_df.columns and 'epoch' in eval_df.columns:
            ax2.plot(eval_df['epoch'], eval_df['eval_loss'], 'r-', label='Validation Loss', linewidth=2, marker='o')
            ax2.set_title('Validation Loss', fontsize=14, fontweight='bold')
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Loss')
            ax2.grid(True, alpha=0.3)
            ax2.legend()

        # Graficar loss de entrenamiento y validación juntos
        if 'loss' in train_df.columns and 'epoch' in train_df.columns and 'eval_loss' in eval_df.columns:
            ax3.plot(train_df['epoch'], train_df['loss'], 'b-', label='Training Loss', linewidth=2, alpha=0.7)
            ax3.plot(eval_df['epoch'], eval_df['eval_loss'], 'r-', label='Validation Loss', linewidth=2, marker='o')
            ax3.set_title('Loss: Training vs Validation', fontsize=14, fontweight='bold')
            ax3.set_xlabel('Epoch')
            ax3.set_ylabel('Loss')
            ax3.grid(True, alpha=0.3)
            ax3.legend()

        # Graficar métricas de validación
        if 'eval_accuracy' in eval_df.columns and 'eval_f1' in eval_df.columns and 'epoch' in eval_df.columns:
            ax4.plot(eval_df['epoch'], eval_df['eval_accuracy'], 'g-', label='Validation Accuracy', linewidth=2, marker='s')
            ax4.plot(eval_df['epoch'], eval_df['eval_f1'], 'purple', label='Validation F1-Score', linewidth=2, marker='^')
            ax4.set_title('Validation Metrics', fontsize=14, fontweight='bold')
            ax4.set_xlabel('Epoch')
            ax4.set_ylabel('Score')
            ax4.grid(True, alpha=0.3)
            ax4.legend()
        elif 'eval_accuracy' in eval_df.columns and 'epoch' in eval_df.columns:
            ax4.plot(eval_df['epoch'], eval_df['eval_accuracy'], 'g-', label='Validation Accuracy', linewidth=2, marker='s')
            ax4.set_title('Validation Accuracy', fontsize=14, fontweight='bold')
            ax4.set_xlabel('Epoch')
            ax4.set_ylabel('Accuracy')
            ax4.grid(True, alpha=0.3)
            ax4.legend()

        plt.tight_layout()
        plt.savefig(f"{output_dir}/training_curves.png", dpi=300, bbox_inches='tight')
        plt.show()

        print(f"Curvas de entrenamiento guardadas en {output_dir}/training_curves.png")

    def plot_combined_metrics(self, output_dir="./vit-lemon-classifier"):
        """Graficar métricas combinadas de entrenamiento y validación"""
        # Cargar historial de entrenamiento
        try:
            with open(f"{output_dir}/training_history.json", "r") as f:
                history = json.load(f)
        except FileNotFoundError:
            print("Historial de entrenamiento no encontrado. Asegúrate de entrenar el modelo primero.")
            return

        eval_logs = history['eval_logs']
        eval_df = pd.DataFrame(eval_logs)

        # Crear subplot para métricas combinadas
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

        # Gráfico de loss combinado
        if 'eval_loss' in eval_df.columns and 'epoch' in eval_df.columns:
            ax1.plot(eval_df['epoch'], eval_df['eval_loss'], 'r-', label='Validation Loss', linewidth=2, marker='o')
            ax1.set_title('Training Progress - Loss', fontsize=14, fontweight='bold')
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Loss')
            ax1.grid(True, alpha=0.3)
            ax1.legend()

        # Gráfico combinado de Accuracy/F1
        if 'eval_accuracy' in eval_df.columns and 'eval_f1' in eval_df.columns and 'epoch' in eval_df.columns:
            ax2.plot(eval_df['epoch'], eval_df['eval_accuracy'], 'g-', label='Validation Accuracy', linewidth=2, marker='s')
            ax2.plot(eval_df['epoch'], eval_df['eval_f1'], 'purple', label='Validation F1-Score', linewidth=2, marker='^')
            ax2.set_title('Training Progress - Metrics', fontsize=14, fontweight='bold')
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Score')
            ax2.grid(True, alpha=0.3)
            ax2.legend()

        plt.tight_layout()
        plt.savefig(f"{output_dir}/combined_metrics.png", dpi=300, bbox_inches='tight')
        plt.show()

        print(f"Gráfico de métricas combinadas guardado en {output_dir}/combined_metrics.png")

# ============================================================================
# PIPELINE PRINCIPAL DE ENTRENAMIENTO
# ============================================================================

if __name__ == "__main__":
    print("Clasificación de Enfermedades de Limón - Pipeline de Fine-tuning ViT")
    print("=" * 60)

    # Inicializar clasificador
    classifier = LemonDiseaseClassifier()

    # Cargar y preprocesar datos
    classifier.load_dataset_and_processor()
    classifier.preprocess_data()

    # Inicializar modelo
    classifier.initialize_model()

    # Configurar argumentos de entrenamiento
    training_args = classifier.setup_training_args(
        output_dir="./vit-lemon-classifier",
        num_epochs=10,
        batch_size=128
    )

    # Entrenar modelo
    classifier.train_model(training_args)

    # Evaluar modelo
    metrics = classifier.evaluate_model("./vit-lemon-classifier")

    # Graficar curvas de entrenamiento
    print("\nGenerando curvas de entrenamiento...")
    classifier.plot_training_curves("./vit-lemon-classifier")
    classifier.plot_combined_metrics("./vit-lemon-classifier")



